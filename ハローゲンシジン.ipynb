{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f740b759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting janome==0.4.1\n",
      "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
      "     --------------------------------------- 19.7/19.7 MB 11.1 MB/s eta 0:00:00\n",
      "Installing collected packages: janome\n",
      "  Attempting uninstall: janome\n",
      "    Found existing installation: Janome 0.4.2\n",
      "    Uninstalling Janome-0.4.2:\n",
      "      Successfully uninstalled Janome-0.4.2\n",
      "Successfully installed janome-0.4.1\n",
      "\n",
      "[notice] A new release of pip available: 22.2 -> 22.2.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install janome==0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7445a32b",
   "metadata": {},
   "source": [
    "### **原始的な形態素解析の第一歩**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75bdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "オレ\t名詞,代名詞,一般,*,*,*,オレ,オレ,オレ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "肉\t名詞,一般,*,*,*,*,肉,ニク,ニク\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "食う\t動詞,自立,*,*,五段・ワ行促音便,基本形,食う,クウ,クウ\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n"
     ]
    }
   ],
   "source": [
    "#Janomeのロード\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "#Tokenizerインスタンスの生成\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#形態素解析の実施\n",
    "tokens = tokenizer.tokenize(\"オレは肉を食う！\")\n",
    "\n",
    "#解析結果の出力：複数の結果が入っており、ループ処理で順番に表示する\n",
    "for token in tokens:\n",
    "    print(token) #各単語の全情報"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e32731",
   "metadata": {},
   "source": [
    "### **Janomeの使い方確認**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8567f5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんばんは\t感動詞,*,*,*,*,*,こんばんは,コンバンハ,コンバンワ\n",
      "コンバンハ\n",
      "None\n",
      "感動詞,*,*,*\n",
      "['感動詞', '*', '*', '*']\n",
      "感動詞\n",
      "-----\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "。\n",
      "None\n",
      "記号,句点,*,*\n",
      "['記号', '句点', '*', '*']\n",
      "記号\n",
      "-----\n",
      "森\t名詞,固有名詞,人名,姓,*,*,森,モリ,モリ\n",
      "モリ\n",
      "None\n",
      "名詞,固有名詞,人名,姓\n",
      "['名詞', '固有名詞', '人名', '姓']\n",
      "名詞\n",
      "-----\n",
      "進一\t名詞,固有名詞,人名,名,*,*,進一,シンイチ,シンイチ\n",
      "シンイチ\n",
      "None\n",
      "名詞,固有名詞,人名,名\n",
      "['名詞', '固有名詞', '人名', '名']\n",
      "名詞\n",
      "-----\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n",
      "デス\n",
      "None\n",
      "助動詞,*,*,*\n",
      "['助動詞', '*', '*', '*']\n",
      "助動詞\n",
      "-----\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "。\n",
      "None\n",
      "記号,句点,*,*\n",
      "['記号', '句点', '*', '*']\n",
      "記号\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "#Janomeのロード\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "#Tokenizerインスタンスの生成\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#形態素解析の実施\n",
    "tokens = tokenizer.tokenize(\"こんばんは。森進一です。\")\n",
    "\n",
    "#解析結果の出力\n",
    "for token in tokens:\n",
    "    print(token) #各単語の全情報\n",
    "    print(token.reading) #ヨミガナ\n",
    "    print(token.baseform) #(動詞などの)原型\n",
    "    print(token.part_of_speech) #品詞情報\n",
    "    print(token.part_of_speech.split(',')) #品詞情報をカンマで区切り、リスト形式に加工\n",
    "    print(token.part_of_speech.split(',')[0]) #[0]でリストの先頭の要素を参照\n",
    "    print(\"-----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c84ff",
   "metadata": {},
   "source": [
    "### **ゲンシゴツール**\n",
    "    - すべてをカタカナに変える。\n",
    "    - 「助詞」を取り除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283856df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コレ  ミンナ ゲンシ ジン  ニク  タベヨ ウ  \n"
     ]
    }
   ],
   "source": [
    "#Janomeをロードする\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "#Tokenizerインスタンス生成\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#形態素解析の実施\n",
    "tokens = tokenizer.tokenize(\"これでみんな原始人。肉を食べよう！\")\n",
    "\n",
    "#tokenが助詞の場合は空文字列、それ以外はヨミガナを返す関数\n",
    "def token2gensigo(input_token):\n",
    "    if input_token.part_of_speech.split(',')[0] == \"助詞\" or  input_token.part_of_speech.split(',')[0] == \"記号\":\n",
    "        return \"\"\n",
    "    else:\n",
    "        return input_token.reading\n",
    "    \n",
    "#各tokenの変換結果を\" \"(半角スペース)でつなげる\n",
    "result_str = \"\"\n",
    "\n",
    "#すべてのtokenに、上で定義したtoken2gensigo関数を実行する\n",
    "for token in tokens:\n",
    "    result_str += token2gensigo(token) + \" \"\n",
    "print(result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee9bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
